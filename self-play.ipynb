{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'env')\n",
    "sys.path.insert(0, 'lib')\n",
    "\n",
    "import ccg\n",
    "from agents import ARagent, A2Cagent, SkipAgent\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import torch\n",
    "import utils\n",
    "seed = 3452342\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "cards = pd.read_csv('env/configue/cardsTable.csv')\n",
    "cardsList = [ccg.Minion(i) for i in cards.values.tolist()]\n",
    "\n",
    "cores = pd.read_csv('env/configue/cores.csv')\n",
    "coreList = [ccg.Core(i) for i in cores.values.tolist()]\n",
    "\n",
    "playersNum = 2\n",
    "piles_player = [ccg.Pile(cardsList, 10) for _ in range(4)]\n",
    "piles = [copy.deepcopy(piles_player) for _ in range(playersNum)]\n",
    "cores = np.random.choice(coreList, 2)\n",
    "decks = [ccg.Deck(cores[i], piles[i], i) for i in range(playersNum)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyName</th>\n",
       "      <th>type</th>\n",
       "      <th>damage</th>\n",
       "      <th>armour</th>\n",
       "      <th>maxHealth</th>\n",
       "      <th>cost</th>\n",
       "      <th>priority</th>\n",
       "      <th>charge</th>\n",
       "      <th>baseActivations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HS_PUDDLESTOMPER</td>\n",
       "      <td>minion</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HS_RIVER_CROCOLISK</td>\n",
       "      <td>minion</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HS_THRALLMAR_FARSEER</td>\n",
       "      <td>minion</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HS_DUSKBOAR</td>\n",
       "      <td>minion</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                keyName    type  damage  armour  maxHealth  cost  priority  \\\n",
       "0      HS_PUDDLESTOMPER  minion       3       0          2     2         0   \n",
       "1    HS_RIVER_CROCOLISK  minion       2       0          3     2         0   \n",
       "2  HS_THRALLMAR_FARSEER  minion       2       0          3     3         0   \n",
       "3           HS_DUSKBOAR  minion       4       0          1     2         0   \n",
       "\n",
       "   charge  baseActivations  \n",
       "0       0                1  \n",
       "1       0                1  \n",
       "2       0                2  \n",
       "3       0                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ccg.Session(cardsList, coreList, 2)\n",
    "session2 = ccg.Session(cardsList, coreList, 2)\n",
    "eval_session = ccg.Session(cardsList, coreList, 2)\n",
    "eval_session2 = ccg.Session(cardsList, coreList, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "from agents import ARagent, A2Cagent\n",
    "from nets import ActorNetwork, ValueNetwork\n",
    "from replays import FlatReplay, PrioritizedReplay\n",
    "import pickle\n",
    "\n",
    "a2cAgent = None\n",
    "\n",
    "with open('best_model_no_en2.pickle', 'rb') as f:\n",
    "    a2cAgent = pickle.load(f)\n",
    "\n",
    "a2cAgentCheckPoint = copy.deepcopy(a2cAgent)\n",
    "a2cAgentCheckPoint.setTraning(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(session, [a2cAgent, a2cAgentCheckPoint])\n",
    "trainer2 = Trainer(session2, [a2cAgentCheckPoint, a2cAgent])\n",
    "eval_trainer = Trainer(session, [a2cAgent, ARagent(1)])\n",
    "eval_trainer2 = Trainer(session2, [ARagent(0), a2cAgent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling buffer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lib\\nets.py:130: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.log_prob(qvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer filled\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "wins = dict()\n",
    "wins[-1] = 0\n",
    "wins[0] = 0\n",
    "wins[1] = 0\n",
    "\n",
    "health_adv_log = []\n",
    "actions_num_log = []\n",
    "turns_log = []\n",
    "wins_log = []\n",
    "entropy_log = []\n",
    "\n",
    "actor_loss_log = []\n",
    "value_loss_log = []\n",
    "\n",
    "actor_loss_epoch = []\n",
    "value_loss_epoch = []\n",
    "\n",
    "print(\"Filling buffer\")\n",
    "for i in range(100):\n",
    "    trainer.playGame(record = True, evaluate = False)\n",
    "    trainer2.playGame(record = True, evaluate = False)\n",
    "print(\"Buffer filled\")       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5f3e2dd6fb39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_games\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mgame_stat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_trainer2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayGame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m                 \u001b[0madv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mturns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwinner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgame_stat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mmean_health_adv\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0madv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\rl_ccg\\lib\\trainer.py\u001b[0m in \u001b[0;36mplayGame\u001b[1;34m(self, session, record, replay_id, evaluate, resetAfterGame)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mplayGame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplay_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresetAfterGame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaySteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplay_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreplay_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresetAfterGame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresetAfterGame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mplaySteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplay_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresetAfterGame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\rl_ccg\\lib\\trainer.py\u001b[0m in \u001b[0;36mplaySteps\u001b[1;34m(self, n_steps, session, record, replay_id, evaluate, resetAfterGame)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mn_steps\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidActions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidActionsEnv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessNewStateInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurAgent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetAction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidActions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidActionsEnv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurSession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0mn_observation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidActions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidActionsEnv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mentropy_log\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mturn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\rl_ccg\\lib\\agents.py\u001b[0m in \u001b[0;36mgetAction\u001b[1;34m(self, observation, validActions, validEnvActions, session, evaluate)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetAction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidActions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidEnvActions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateStateObservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[0mlog_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_qvalues_from_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mrand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\rl_ccg\\lib\\utils.py\u001b[0m in \u001b[0;36mcreateStateObservation\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mobservations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0mobservations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"table\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobservationTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"battleGround\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"table\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[0mobservations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"piles\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mobservations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hands\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\rl_ccg\\lib\\utils.py\u001b[0m in \u001b[0;36mobservationTable\u001b[1;34m(table)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mtables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtables_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mtables_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtables_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;31m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0marrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for self_iters in range(10):\n",
    "    cur_score = -60\n",
    "    cur_checkpoint = None\n",
    "    \n",
    "    prev_score = -60\n",
    "    mean_wins = 0\n",
    "    eval_games = 100\n",
    "\n",
    "    for i in range(eval_games // 2):\n",
    "        game_stat, _ = eval_trainer.playGame(record = False, evaluate = True)\n",
    "        adv, actions_num, turns, winner = game_stat\n",
    "        mean_wins += winner[0]\n",
    "\n",
    "    for i in range(eval_games // 2):\n",
    "        game_stat, _ = eval_trainer2.playGame(record = False, evaluate = True)\n",
    "        adv, actions_num, turns, winner = game_stat\n",
    "        mean_wins += winner[1]\n",
    "\n",
    "\n",
    "    prev_score = mean_wins / eval_games\n",
    "    \n",
    "    \n",
    "    for i in range(600):\n",
    "        for j in range(30):\n",
    "            trainer.playSteps(10, replay_id = str(i)+\" \"+str(j)+\"1\")\n",
    "            trainer2.playSteps(10, replay_id = str(i)+\" \"+str(j)+\"2\")\n",
    "        observation, _, _ = session.processNewStateInfo()\n",
    "        winner = -1\n",
    "        if(observation[\"loser\"] != -1):\n",
    "            winner = 1 - observation[\"loser\"]\n",
    "        wins[winner] += 1\n",
    "\n",
    "        actor_loss, value_loss = trainer.train()[0]\n",
    "        actor_loss2, value_loss2 = trainer2.train()[1]\n",
    "\n",
    "        actor_loss_epoch.append((actor_loss + actor_loss2) / 2)\n",
    "        value_loss_epoch.append((value_loss + value_loss2) / 2)\n",
    "\n",
    "        if True:#(i % 50 == 0):\n",
    "            clear_output()\n",
    "            eval_games = 100\n",
    "            mean_health_adv = 0\n",
    "            mean_actions_num = 0\n",
    "            mean_turns = 0\n",
    "            mean_wins = 0\n",
    "            mean_entropy = []\n",
    "\n",
    "            for i in range(eval_games // 2):\n",
    "                game_stat, entropy = eval_trainer.playGame(record = False, evaluate = True)\n",
    "                adv, actions_num, turns, winner = game_stat\n",
    "                mean_health_adv += adv[0]\n",
    "                mean_actions_num += actions_num[0]\n",
    "                mean_turns += turns\n",
    "                mean_wins += winner[0]\n",
    "                mean_entropy.extend(entropy[0])\n",
    "\n",
    "            for i in range(eval_games // 2):\n",
    "                game_stat, entropy = eval_trainer2.playGame(record = False, evaluate = True)\n",
    "                adv, actions_num, turns, winner = game_stat\n",
    "                mean_health_adv += adv[1]\n",
    "                mean_actions_num += actions_num[1]\n",
    "                mean_turns += turns\n",
    "                mean_wins += winner[1]\n",
    "                mean_entropy.extend(entropy[1])\n",
    "\n",
    "\n",
    "            health_adv_log.append(mean_health_adv / eval_games)\n",
    "            actions_num_log.append(mean_actions_num / eval_games)\n",
    "            turns_log.append(mean_turns / eval_games)\n",
    "            wins_log.append(mean_wins / eval_games)\n",
    "            entropy_log.append(np.mean(mean_entropy))\n",
    "\n",
    "            if mean_wins / eval_games > cur_score:\n",
    "                cur_score = mean_wins / eval_games\n",
    "                cur_checkpoint = copy.deepcopy(a2cAgent)\n",
    "\n",
    "            print(cur_score)\n",
    "\n",
    "            value_loss_log.append(np.mean(value_loss_epoch))\n",
    "            actor_loss_log.append(np.mean(actor_loss_epoch))\n",
    "\n",
    "            acotor_loss_epoch = []\n",
    "            value_loss_epoch = []\n",
    "\n",
    "            fig = plt.figure(figsize=(13, 13))\n",
    "\n",
    "            plt.subplot(3, 3, 1)\n",
    "            plt.plot(range(len(health_adv_log)), health_adv_log)\n",
    "            plt.title(\"Health advantage\")\n",
    "\n",
    "            plt.subplot(3, 3, 2)\n",
    "            plt.plot(range(len(actions_num_log)), actions_num_log)\n",
    "            plt.title(\"Actions num\")\n",
    "\n",
    "            plt.subplot(3, 3, 3)\n",
    "            plt.plot(range(len(turns_log)), turns_log)\n",
    "            plt.title(\"Turns num\")\n",
    "\n",
    "            plt.subplot(3, 3, 4)\n",
    "            plt.plot(range(len(wins_log)), wins_log)\n",
    "            plt.title(\"Win rate\")\n",
    "\n",
    "            plt.subplot(3, 3, 5)\n",
    "            plt.plot(range(len(actor_loss_log)), actor_loss_log)\n",
    "            plt.title(\"Actor loss\")\n",
    "\n",
    "            plt.subplot(3, 3, 6)\n",
    "            plt.plot(range(len(value_loss_log)), value_loss_log)\n",
    "            plt.title(\"Critic loss\")\n",
    "\n",
    "            plt.subplot(3, 3, 7)\n",
    "            plt.plot(range(len(entropy_log)), entropy_log)\n",
    "            plt.title(\"Entropy\")\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "    if(cur_score > prev_score):\n",
    "        prev_score = cur_score\n",
    "        a2cAgentCheckPoint = copy.deepcopy(a2cAgent)\n",
    "        a2cAgentCheckPoint.setTraning(False)\n",
    "        trainer = Trainer(session, [a2cAgent, a2cAgentCheckPoint])\n",
    "        trainer2 = Trainer(session2, [a2cAgentCheckPoint, a2cAgent])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_self_play_model_no_en2.pickle', 'wb') as f:\n",
    "    pickle.dump(a2cAgent, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
